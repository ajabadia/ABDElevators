{
  "title": "RAG Evaluation Dashboard",
  "subtitle": "Observability and response quality (Faithfulness, Relevance, Precision)",
  "judge_badge": "LLM Judge: Gemini 1.5 Pro",
  "metrics": {
    "faithfulness": "Faithfulness (Avg)",
    "relevance": "Answer Relevance",
    "precision": "Context Precision",
    "queries": "Evaluated Queries",
    "faithfulness_desc": "Answers based only on context",
    "relevance_desc": "Answer pertinence",
    "precision_desc": "Utility of retrieved context",
    "queries_desc": "Total analyzed traces"
  },
  "tabs": {
    "trends": "Quality Trends",
    "history": "Trace History"
  },
  "chart": {
    "title": "Metrics Evolution",
    "desc": "Daily tracking of faithfulness and relevance of responses",
    "faithfulness": "Faithfulness",
    "relevance": "Relevance"
  },
  "table": {
    "date": "Date",
    "query": "Query",
    "metrics": "Metrics (F|R|P)",
    "feedback": "Judge Feedback"
  }
}